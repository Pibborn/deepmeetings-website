<div class="modal-header">
    <h5 class="modal-title" id="exampleModalLabel">Extraction of Knowledge Automata from RNNs</h5>
    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
<span aria-hidden="true">&times;</span>
</button>
</div>
<div class="modal-body">
    <div class="row">
        <div class="col-md-4">
            <div class="modal-author-side">
                <div class="modal-author-avatar">
                    <figure>
                        <img src="./img/avatars/alessandro.jpg" class="rounded-circle speaker-avatar">
                    </figure>
                </div>

                <div class="modal-author-description">
                    <div class="speaker">
                        Speaker:
                    </div>
                    Alessandro Mazzei
                </div>
                <div class="modal-author-icons">
                    <a href="http://www.di.unito.it/~mazzei/AlessandroHomepage/home.html"><span class="octicon octicon-globe"></span></a>
                    <a href="mailto:mazzei@di.unito.it"><span class="octicon octicon-mail"></span></a>
                </div>
            </div>
        </div>
        <div class="col-md-8">
            <div class="modal-description-side">
                An issue with complex neural network models is certainly interpretability and understanding of which concepts
                have been inferred from the data by the network. A possible approach to interpret a RNN model is extracting
                an automaton that describes the state dynamics of the network, which is the focus of the paper presented in this
                installment.
            </div>
        </div>
    </div>
</div>
<div class="modal-footer">
    <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
    <a href="./slides/automaton.pdf"
       class="btn btn-primary" role="button">
       Get the slides
    </a>
</div>
